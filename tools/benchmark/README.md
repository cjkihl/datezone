# ğŸš€ Datezone Benchmark Suite

Comprehensive, fair, and readable performance comparisons between Datezone and Date-fns (with timezone support).

## Quick Start

Generate a beautiful comparison report:

```bash
# From workspace root
bun run bench:comprehensive --json   # Step 1: Run all benchmarks, output JSON
bun run tools/benchmark/create-comparison-report.ts   # Step 2: Generate markdown report
```

## ğŸƒ Benchmark Runner (`run.ts`)

- Finds all `*.bench.ts` files in `packages/datezone/`.
- Runs each benchmark serially using Bun.
- **Arguments:**
  - `--json` â€” Output results as JSON (for report generation)
  - `--filter <names>` or `-F <names>` â€” Run only specific benchmarks (comma-separated, e.g. `day,month`)

**Examples:**
```bash
bun run bench:comprehensive --json
bun run bench:comprehensive --filter day,month
```

## ğŸ† Available Commands

| Command | Description | Output |
|---------|-------------|--------|
| `bun run bench:comprehensive [--json] [--filter <names>]` | Run all (or filtered) benchmarks, optionally outputting JSON | `output/output.json` (if `--json`)
| `bun run bench:report` | Generate the main comparison report (pretty tables) | `reports/comparison-report.md` |
| `bun run tools/benchmark/create-comparison-report.ts` | (Alternative) Generate the comparison report from JSON | `reports/comparison-report.md` |
| `bun run tools/benchmark/create-full-report.ts` | Aggregate all raw markdown benchmark reports | `reports/full-benchmarks.md` |
| `bun run bench:clean` | Clean all output and report files | - |
| `bun run bench` | Datezone-only microbenchmarks (internal, not comparison) | - |
| `bun run quick` | Quick comparison run (not comprehensive) | - |

## ğŸ“ Output Files

- `output/output.json` â€” Raw Mitata JSON output (from `--json` run)
- `reports/comparison-report.md` â€” Formatted markdown comparison report
- `reports/full-benchmarks.md` â€” All raw benchmark markdowns, consolidated

## ğŸ› ï¸ How It Works

1. **Run Benchmarks:**
   - `bun run bench:comprehensive --json`
   - Runs all benchmarks and writes results as JSON to `output/output.json` (using Mitata's `print` option).
   - Use `--filter` to run a subset.
2. **Generate Comparison Report:**
   - `bun run tools/benchmark/create-comparison-report.ts`
   - Reads the JSON output and generates a markdown report in `reports/comparison-report.md`.
3. **Generate Full Raw Report:**
   - `bun run tools/benchmark/create-full-report.ts`
   - Aggregates all raw markdown benchmark reports from `packages/datezone/.bench/*.md` into `reports/full-benchmarks.md`.
4. **Clean Outputs:**
   - `bun run bench:clean`
   - Removes all files in `output/` and `reports/`.

## ğŸ¯ Report Features

- ğŸš€ **Datezone dominates** (>100% faster)
- âš¡ **Datezone wins** (25-100% faster)
- âœ… **Datezone leads** (10-25% faster)
- ğŸ¤ **Close match** (<10% difference)
- âš ï¸ **Date-fns leads** (10-25% faster)
- ğŸŒ **Date-fns wins** (>25% faster)
- ğŸ”¥ **Datezone only** (no equivalent)

## ğŸ”§ Technical Details

- **Timezone-aware operations** (fair comparison)
- **Month/day/time manipulations**
- **Formatting and parsing**
- **Unique Datezone utilities**
- **Datezone:** Built-in timeZone support
- **Date-fns v4:** With `@date-fns/tz` package
- [Mitata](https://github.com/evanwashere/mitata) â€” High-precision JavaScript benchmarking

## ğŸ› ï¸ How to Regenerate Reports

### Comparison Report
```bash
bun run bench:comprehensive --json
bun run tools/benchmark/create-comparison-report.ts
```

### Full Raw Report
```bash
bun run bench:comprehensive
bun run tools/benchmark/create-full-report.ts
```

---

*Made with â¤ï¸ to make benchmark results actually readable*
